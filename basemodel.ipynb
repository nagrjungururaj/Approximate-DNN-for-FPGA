{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tkinter\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.datasets import mnist,cifar10,cifar100,fashion_mnist\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Input,Reshape,concatenate\n",
    "from keras import optimizers\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "import keras.backend as K\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intialize some global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 64\n",
    "epoch = 5\n",
    "num_classes1 = 10\n",
    "num_classes2 = 26\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_input(x):\n",
    "    if x == 'mnist':\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "        return (x_train, y_train), (x_test, y_test)\n",
    "    else:\n",
    "        if x == 'cifar10':\n",
    "            (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "            return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "        else:\n",
    "            if x == 'cifar100':\n",
    "                (x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='coarse')\n",
    "                return (x_train, y_train), (x_test, y_test)\n",
    "            else:\n",
    "                if x == 'fashion_mnist':\n",
    "                    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "                    return (x_train, y_train), (x_test, y_test)\n",
    "                else:\n",
    "                    if x == 'svhn':\n",
    "                        x_train = loadmat('/home/nagarjun/datasets/svhn_cnn/x_train.mat')\n",
    "                        x_test = loadmat('/home/nagarjun/datasets/svhn_cnn/x_test.mat')\n",
    "                        y_train = loadmat('/home/nagarjun/datasets/svhn_cnn/y_train.mat')\n",
    "                        y_test = loadmat('/home/nagarjun/datasets/svhn_cnn/y_test.mat')\n",
    "                        x_train = x_train['x_train']\n",
    "                        x_test = x_test['x_test']\n",
    "                        y_train = y_train['y_train']\n",
    "                        y_test = y_test['y_test']\n",
    "\n",
    "                        return (x_train, y_train-1), (x_test, y_test-1)\n",
    "\n",
    "                    else:\n",
    "                        if x == 'nist_char':\n",
    "                            x_train = loadmat('/home/nagarjun/datasets/nist_char_cnn/x_train.mat')\n",
    "                            x_test = loadmat('/home/nagarjun/datasets/nist_char_cnn/x_test.mat')\n",
    "                            y_train = loadmat('/home/nagarjun/datasets/nist_char_cnn/y_train.mat')\n",
    "                            y_test = loadmat('/home/nagarjun/datasets/nist_char_cnn/y_test.mat')\n",
    "                            x_train = x_train['x_train']\n",
    "                            x_test = x_test['x_test']\n",
    "                            y_train = y_train['y_train']\n",
    "                            y_test = y_test['y_test']\n",
    "                            return (x_train, y_train - 1), (x_test, y_test - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the 1D LeNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet_CNN(x):\n",
    "\n",
    "    if x == 'mnist' or x == 'fashion_mnist' or x == 'nist_char':\n",
    "\n",
    "        input = Input(shape=(x_train.shape[1],))\n",
    "\n",
    "        conv1 = Dense(3456,activation='relu')(input)\n",
    "        conv1 = Reshape(target_shape=(24, 24, 6))(conv1)\n",
    "\n",
    "        pool1 = MaxPooling2D((2,2))(conv1)\n",
    "        pool1 = Reshape(target_shape=(12*12*6,))(pool1)\n",
    "\n",
    "        conv2 = Dense(1024,activation='relu')(pool1)\n",
    "        conv2 = Reshape(target_shape=(8,8,16))(conv2)\n",
    "        pool2 = MaxPooling2D((2,2))(conv2)\n",
    "        pool2 = Flatten()(pool2)\n",
    "\n",
    "        dense1 = Dense(120,activation='relu')(pool2)\n",
    "        dense2 = Dense(84,activation='relu')(dense1)\n",
    "        if x == 'mnist':\n",
    "            out = Dense(num_classes1,activation='softmax')(dense2)\n",
    "        else:\n",
    "            if x == 'fashion_mnist':\n",
    "                out = Dense(num_classes1, activation='softmax')(dense2)\n",
    "            else:\n",
    "                out = Dense(num_classes2, activation='softmax')(dense2)\n",
    "\n",
    "        model = Model(input,out)\n",
    "        return model\n",
    "\n",
    "    else:\n",
    "        if x == 'cifar10' or x =='svhn':\n",
    "\n",
    "            in1 = Input(shape=(x_train1.shape[1],))\n",
    "\n",
    "            out1 = Dense(4704, activation='relu')(in1)\n",
    "\n",
    "            in2 = Input(shape= (x_train2.shape[1],))\n",
    "            out2 = Dense(4704, activation='relu')(in2)\n",
    "\n",
    "            in3 = Input(shape= (x_train3.shape[1],))\n",
    "            out3 = Dense(4704, activation='relu')(in3)\n",
    "\n",
    "            #input = concatenate([in1, in2, in3])\n",
    "\n",
    "            conv1 = concatenate([out1, out2, out3])\n",
    "\n",
    "            conv1 = Reshape(target_shape=(28, 28, 18))(conv1)\n",
    "\n",
    "            pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "            pool1 = Reshape(target_shape=(14 * 14 * 18,))(pool1)\n",
    "\n",
    "            conv2 = Dense(1600, activation='relu')(pool1)\n",
    "            conv2 = Reshape(target_shape=(10, 10, 16))(conv2)\n",
    "            pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "            pool2 = Flatten()(pool2)\n",
    "\n",
    "            dense1 = Dense(120, activation='relu')(pool2)\n",
    "            dense2 = Dense(84, activation='relu')(dense1)\n",
    "            out = Dense(num_classes1, activation='softmax')(dense2)\n",
    "\n",
    "            model = Model([in1,in2,in3], out)\n",
    "            return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trained_model(x):\n",
    "    \n",
    "    if x == 'mnist':\n",
    "        # serialize model to JSON\n",
    "        model_json1 = model.to_json()\n",
    "        with open(\"model.json1\", \"w\") as json_file:\n",
    "            json_file.write(model_json1)\n",
    "        # serialize weights to HDF5\n",
    "        model.save_weights('/home/nagarjun/datasets/trained_models/mnist_cnn_model.h5')\n",
    "        print(\"Saved model to disk\")\n",
    "\n",
    "    else:\n",
    "        if x == 'fashion_mnist':\n",
    "            # serialize model to JSON\n",
    "            model_json2 = model.to_json()\n",
    "            with open(\"model.json2\", \"w\") as json_file:\n",
    "                json_file.write(model_json2)\n",
    "            # serialize weights to HDF5\n",
    "            model.save_weights('os.path.join(path,'trained_models',fashion_mnist_cnn_model.h5'))\n",
    "            print(\"Saved model to disk\")\n",
    "        else:\n",
    "            if x == 'nist_char':\n",
    "                # serialize model to JSON\n",
    "                model_json3 = model.to_json()\n",
    "                with open(\"model.json3\", \"w\") as json_file:\n",
    "                    json_file.write(model_json3)\n",
    "                # serialize weights to HDF5\n",
    "                model.save_weights(os.path.join(path,'trained_models','nist_cnn_model.h5'))\n",
    "                print(\"Saved model to disk\")\n",
    "            else:\n",
    "                if x == 'cifar10':\n",
    "                    # serialize model to JSON\n",
    "                    model_json4 = model.to_json()\n",
    "                    with open(\"model.jsoncifar\", \"w\") as json_file:\n",
    "                        json_file.write(model_json4)\n",
    "                    # serialize weights to HDF5\n",
    "                    model.save_weights(os.path.join(path,'trained_models','cifar10_cnn_model.h5'))\n",
    "                    print(\"Saved model to disk\")\n",
    "                else:\n",
    "                    if x == 'svhn':\n",
    "                        # serialize model to JSON\n",
    "                        model_json5 = model.to_json()\n",
    "                        with open(\"model.jsonsvhn\", \"w\") as json_file:\n",
    "                            json_file.write(model_json5)\n",
    "                        # serialize weights to HDF5\n",
    "                        model.save_weights(os.path.join(path,'trained_models','svhn_cnn_model.h5'))\n",
    "                        print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load model + inputs \n",
    "2. Compile model \n",
    "3. Fit the model\n",
    "4. Evaluate model with metrics Top-1 accuracy, Top-5, Precision, Recall and F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'cifar10' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-200daeec0c14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-e5ce573eb2a9>\u001b[0m in \u001b[0;36mload_input\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'cifar10'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'cifar10' is not defined"
     ]
    }
   ],
   "source": [
    "x = ['mnist','fashion_mnist','nist_char','cifar10','svhn']\n",
    "\n",
    "for j in range(len(x)):\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = load_input(x[j])\n",
    "\n",
    "    x_train = x_train/255\n",
    "    x_test = x_test/255\n",
    "\n",
    "    if x[j] == 'mnist' or x[j] == 'fashion_mnist':\n",
    "\n",
    "        y_train = keras.utils.to_categorical(y_train, num_classes=num_classes1)\n",
    "        y_test = keras.utils.to_categorical(y_test, num_classes=num_classes1)\n",
    "\n",
    "        [num_images_train,m,n] = np.shape(x_train)\n",
    "        [num_images_test,_,_]  = np.shape(x_test)\n",
    "\n",
    "        x_train = np.reshape(x_train,[num_images_train,m,n,1])\n",
    "        x_test = np.reshape(x_test,[num_images_test,m,n,1])\n",
    "\n",
    "        [num_images_train, m, n,channels] = np.shape(x_train)\n",
    "    else:\n",
    "        if x[j] == 'cifar10' or x[j] == 'svhn':\n",
    "            y_train = keras.utils.to_categorical(y_train, num_classes=num_classes1)\n",
    "            y_test = keras.utils.to_categorical(y_test, num_classes=num_classes1)\n",
    "\n",
    "            x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1] * x_train.shape[2] * x_train.shape[3]))\n",
    "            x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1] * x_test.shape[2] * x_test.shape[3]))\n",
    "\n",
    "            print(x_train.shape)\n",
    "\n",
    "            # [num_images_train, m, n,channels] = np.shape(x_train)\n",
    "            # [num_images_test, _, _,_] = np.shape(x_test)\n",
    "\n",
    "        else:\n",
    "            if x[j] == 'nist_char':\n",
    "\n",
    "                y_train = keras.utils.to_categorical(y_train, num_classes=num_classes2)\n",
    "                y_test = keras.utils.to_categorical(y_test, num_classes=num_classes2)\n",
    "\n",
    "                [num_images_train, m, n] = np.shape(x_train)\n",
    "                [num_images_test,_,_] = np.shape(x_test)\n",
    "\n",
    "                x_train = np.reshape(x_train, [num_images_train, m, n, 1])\n",
    "                x_test = np.reshape(x_test, [num_images_test, m, n, 1])\n",
    "\n",
    "                [num_images_train, m, n, channels] = np.shape(x_train)\n",
    "\n",
    "    model = select_model(x[j])\n",
    "    print(model.summary())\n",
    "\n",
    "    model.compile(optimizer=optimizers.Adam(lr),loss='categorical_crossentropy',metrics=['accuracy','top_k_categorical_accuracy'])\n",
    "\n",
    "    model.fit(x_train,y_train,batch_size=batchsize,epochs=epoch,verbose=0)\n",
    "\n",
    "    [loss_test,score,top5] = model.evaluate(x_test,y_test,batch_size=batchsize,verbose=0)\n",
    "    print(x[j],'\\n')\n",
    "\n",
    "    print('Test Accuracy\\n',score,top5)\n",
    "\n",
    "    y_pred_test = model.predict(x_test, batch_size=batchsize)\n",
    "\n",
    "    precision_test = precision_score(y_test, y_pred_test.round(), average='micro')\n",
    "    recall_test = recall_score(y_test, y_pred_test.round(), average='micro')\n",
    "\n",
    "    #f1_train = f1_score(y_train, y_pred_train.round(), average='micro')\n",
    "    f1_test = f1_score(y_test, y_pred_test.round(), average='micro')\n",
    "\n",
    "    print('Precision-test:\\n', precision_test)\n",
    "    print('Recall-test:\\n', recall_test)\n",
    "\n",
    "    print('F1-score-test:\\n', f1_test)\n",
    "\n",
    "    save_trained_model(x[j])\n",
    "\n",
    "    K.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
